{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c4c5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:02.529070Z",
     "iopub.status.busy": "2023-06-25T08:55:02.528611Z",
     "iopub.status.idle": "2023-06-25T08:55:05.427951Z",
     "shell.execute_reply": "2023-06-25T08:55:05.426714Z"
    },
    "id": "5CIX_9AC47SA",
    "papermill": {
     "duration": 2.911799,
     "end_time": "2023-06-25T08:55:05.431124",
     "exception": false,
     "start_time": "2023-06-25T08:55:02.519325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from numerapi import NumerAPI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import lightgbm\n",
    "import json\n",
    "from collections import Counter\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model, name):\n",
    "    try:\n",
    "        Path(\"models\").mkdir(exist_ok=True, parents=True)\n",
    "    except Exception as ex:\n",
    "        pass\n",
    "    pd.to_pickle(model, f\"models/{name}.pkl\")\n",
    "\n",
    "\n",
    "def load_model(model_folder, name):\n",
    "    path = Path(f\"{model_folder}/{name}.pkl\")\n",
    "    if path.is_file():\n",
    "        model = pd.read_pickle(f\"{model_folder}/{name}.pkl\")\n",
    "    else:\n",
    "        model = False\n",
    "    return model\n",
    "\n",
    "def save_prediction(prediction, name):\n",
    "    try:\n",
    "        Path(\"predictions\").mkdir(exist_ok=True, parents=True)\n",
    "    except Exception as ex:\n",
    "        pass\n",
    "    pd.to_pickle(prediction, f\"predictions/{name}.pkl\")\n",
    "\n",
    "# napi = NumerAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180f3820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:05.447623Z",
     "iopub.status.busy": "2023-06-25T08:55:05.447197Z",
     "iopub.status.idle": "2023-06-25T08:55:05.452781Z",
     "shell.execute_reply": "2023-06-25T08:55:05.451477Z"
    },
    "id": "3zJlE8O05D7S",
    "outputId": "82d5fead-52cd-4094-8f57-f7a9c16b2d7f",
    "papermill": {
     "duration": 0.016868,
     "end_time": "2023-06-25T08:55:05.455420",
     "exception": false,
     "start_time": "2023-06-25T08:55:05.438552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# napi.download_dataset(\"v4.1/train_int8.parquet\", \"train_int8.parquet\")\n",
    "# napi.download_dataset(\"v4.1/validation_int8.parquet\", \"validation_int8.parquet\")\n",
    "# napi.download_dataset(\"v4.1/features.json\", \"features.json\")\n",
    "\n",
    "path = \"/kaggle/input/numerai-latest-tournament-data/v4.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d1061d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:05.471843Z",
     "iopub.status.busy": "2023-06-25T08:55:05.470902Z",
     "iopub.status.idle": "2023-06-25T08:55:05.521957Z",
     "shell.execute_reply": "2023-06-25T08:55:05.520896Z"
    },
    "id": "qnh4seri6c0Q",
    "papermill": {
     "duration": 0.062048,
     "end_time": "2023-06-25T08:55:05.524623",
     "exception": false,
     "start_time": "2023-06-25T08:55:05.462575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "18 18\n"
     ]
    }
   ],
   "source": [
    "with open(path+\"features.json\", \"r\") as f:\n",
    "    feature_metadata = json.load(f)\n",
    "features = feature_metadata[\"feature_sets\"][\"medium\"]\n",
    "print(len(features))\n",
    "\n",
    "targets = feature_metadata[\"targets\"][1:]\n",
    "targets_v20 = [t for t in targets if t.endswith('20') == True]\n",
    "targets_v60 = [t for t in targets if t.endswith('60') == True]\n",
    "\n",
    "print(len(targets_v20), len(targets_v60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c88278f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:05.542084Z",
     "iopub.status.busy": "2023-06-25T08:55:05.541345Z",
     "iopub.status.idle": "2023-06-25T08:55:05.546977Z",
     "shell.execute_reply": "2023-06-25T08:55:05.545717Z"
    },
    "papermill": {
     "duration": 0.01755,
     "end_time": "2023-06-25T08:55:05.549527",
     "exception": false,
     "start_time": "2023-06-25T08:55:05.531977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 60\n",
    "\n",
    "if(TARGET == 20):\n",
    "    targets = targets_v20\n",
    "    divide = 4\n",
    "elif(TARGET == 60):\n",
    "    targets = targets_v60\n",
    "    divide = 12\n",
    "else:\n",
    "    print(\"error, TARGET has to be 20 or 60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7926e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:05.567659Z",
     "iopub.status.busy": "2023-06-25T08:55:05.567026Z",
     "iopub.status.idle": "2023-06-25T08:55:47.738899Z",
     "shell.execute_reply": "2023-06-25T08:55:47.737426Z"
    },
    "id": "KjEFvbnS6ALo",
    "papermill": {
     "duration": 42.191065,
     "end_time": "2023-06-25T08:55:47.748003",
     "exception": false,
     "start_time": "2023-06-25T08:55:05.556938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412928, 661)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(path+'train_int8.parquet', columns=['id', 'era'] + targets + features).reset_index()\n",
    "train_df.loc[:, \"era\"] = train_df.era.astype(int)\n",
    "validation_df = pd.read_parquet(path+'validation_int8.parquet', columns=['id', 'era'] + targets + features).reset_index()\n",
    "validation_df.loc[:, \"era\"] =validation_df.era.astype(int)\n",
    "\n",
    "train_df = train_df.loc[lambda x: (x.era%divide) == 0]\n",
    "validation_df = validation_df.loc[lambda x: (x.era%divide) == 0]\n",
    "\n",
    "all_data = pd.concat([train_df, validation_df])\n",
    "print(all_data.shape)\n",
    "del train_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4992f059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:47.765727Z",
     "iopub.status.busy": "2023-06-25T08:55:47.764386Z",
     "iopub.status.idle": "2023-06-25T08:55:47.776876Z",
     "shell.execute_reply": "2023-06-25T08:55:47.775448Z"
    },
    "papermill": {
     "duration": 0.02446,
     "end_time": "2023-06-25T08:55:47.779992",
     "exception": false,
     "start_time": "2023-06-25T08:55:47.755532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  12   24   36   48   60   72   84   96  108  120  132  144  156  168\n",
      "  180  192  204  216  228  240  252  264  276  288  300  312  324  336\n",
      "  348  360  372  384  396  408  420  432  444  456  468  480  492  504\n",
      "  516  528  540  552  564  576  588  600  612  624  636  648  660  672\n",
      "  684  696  708  720  732  744  756  768  780  792  804  816  828  840\n",
      "  852  864  876  888  900  912  924  936  948  960  972  984  996 1008\n",
      " 1020 1032 1044 1056 1068]\n"
     ]
    }
   ],
   "source": [
    "print(all_data['era'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ae560a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:47.797955Z",
     "iopub.status.busy": "2023-06-25T08:55:47.797273Z",
     "iopub.status.idle": "2023-06-25T08:55:53.679502Z",
     "shell.execute_reply": "2023-06-25T08:55:53.678226Z"
    },
    "papermill": {
     "duration": 5.894627,
     "end_time": "2023-06-25T08:55:53.682605",
     "exception": false,
     "start_time": "2023-06-25T08:55:47.787978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up NAs\n",
      "Cleaned up NAs\n"
     ]
    }
   ],
   "source": [
    "# Int8 datatype has pd.NA which don't play nice with models.  We simply fill NA with median values here\n",
    "print(\"Cleaning up NAs\")\n",
    "all_data[features] = all_data[features].fillna(all_data[features].median(skipna=True)).astype(\"int8\")\n",
    "# Alternatively could convert nan columns to be floats and replace pd.NA with np.nan\n",
    "print(\"Cleaned up NAs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a649a",
   "metadata": {
    "id": "lFzthURc_hFo",
    "papermill": {
     "duration": 0.007279,
     "end_time": "2023-06-25T08:55:53.698079",
     "exception": false,
     "start_time": "2023-06-25T08:55:53.690800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train models on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fa40a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:53.715204Z",
     "iopub.status.busy": "2023-06-25T08:55:53.714813Z",
     "iopub.status.idle": "2023-06-25T08:55:53.721347Z",
     "shell.execute_reply": "2023-06-25T08:55:53.720168Z"
    },
    "id": "OFKiZ1Jf7abW",
    "papermill": {
     "duration": 0.01796,
     "end_time": "2023-06-25T08:55:53.723803",
     "exception": false,
     "start_time": "2023-06-25T08:55:53.705843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params_name = \"lg_lgbm\"\n",
    "params = {\n",
    "    \"n_estimators\": 20000,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"max_depth\": 6,\n",
    "    \"num_leaves\": 2**6,\n",
    "    \"colsample_bytree\": 0.1,\n",
    "}\n",
    "# Very small fast params\n",
    "# params_name = \"vsm_lgbm\"\n",
    "# params = {\"n_estimators\": 2,\n",
    "#           \"learning_rate\": 1,\n",
    "#           \"max_depth\": 2,\n",
    "#           \"num_leaves\": 2 ** 2,\n",
    "#           \"colsample_bytree\": 0.1}\n",
    "\n",
    "model_obj = lightgbm.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba28f8d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-06-25T08:55:53.741968Z",
     "iopub.status.busy": "2023-06-25T08:55:53.740901Z",
     "iopub.status.idle": "2023-06-25T13:01:10.839871Z",
     "shell.execute_reply": "2023-06-25T13:01:10.836535Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 14717.138364,
     "end_time": "2023-06-25T13:01:10.870228",
     "exception": false,
     "start_time": "2023-06-25T08:55:53.731864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model_target_nomi_v4_60_10000_v60\n",
      "Completed: training model_target_nomi_v4_60_10000_v60\n",
      "training model_target_nomi_v4_60_888_v60\n",
      "Completed: training model_target_nomi_v4_60_888_v60\n",
      "training model_target_tyler_v4_60_10000_v60\n",
      "Completed: training model_target_tyler_v4_60_10000_v60\n",
      "training model_target_tyler_v4_60_888_v60\n",
      "Completed: training model_target_tyler_v4_60_888_v60\n",
      "training model_target_victor_v4_60_10000_v60\n",
      "Completed: training model_target_victor_v4_60_10000_v60\n",
      "training model_target_victor_v4_60_888_v60\n",
      "Completed: training model_target_victor_v4_60_888_v60\n",
      "CPU times: user 14h 11min 11s, sys: 15min 59s, total: 14h 27min 11s\n",
      "Wall time: 4h 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# corr = []\n",
    "\n",
    "# for counter, train_eras in enumerate(train_data_library):\n",
    "for target in targets[:3]:\n",
    "    for subset in [10000, 888]:\n",
    "        print(f\"training model_{target}_{subset}_v60\")\n",
    "        model_obj.fit(all_data[all_data[\"era\"] < subset].loc[:, features], all_data[all_data[\"era\"] < subset].loc[:,target])\n",
    "        save_model(model_obj, f\"model_{target}_{subset}_v60\")\n",
    "#     # Load model\n",
    "#     model_obj = load_model(\"/kaggle/input/numerai-recent-eras-hypo-train-on-val-set/models/\",f\"model_{counter}\")\n",
    "#     # VPredict on validation data to check performance (we want to maximize corr with validation data but also not overfit)\n",
    "#     print(\"Predicting on validation\")\n",
    "#     pred_hillclimb = model_obj.predict(validation_df.loc[:, features])\n",
    "#     validation_df.loc[:, 'pred_{}'.format(counter)] = pred_hillclimb\n",
    "#     # Predict on live to get correlation with live model (we want to minimize corr with live model)\n",
    "#     print(\"Predicting on live\")\n",
    "#     pred_live = model_obj.predict(live_df.loc[:, features])\n",
    "#     live_df.loc[:, 'pred_{}'.format(counter)] = pred_live\n",
    "    \n",
    "        print(f'Completed: training model_{target}_{subset}_v60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9ebac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:10.894294Z",
     "iopub.status.busy": "2023-06-25T13:01:10.893774Z",
     "iopub.status.idle": "2023-06-25T13:01:10.900919Z",
     "shell.execute_reply": "2023-06-25T13:01:10.899870Z"
    },
    "papermill": {
     "duration": 0.024517,
     "end_time": "2023-06-25T13:01:10.903519",
     "exception": false,
     "start_time": "2023-06-25T13:01:10.879002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_cols = [c for c in validation_df.columns if (c.startswith('pred'))]\n",
    "# (pred_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29900b",
   "metadata": {
    "papermill": {
     "duration": 0.00864,
     "end_time": "2023-06-25T13:01:10.920942",
     "exception": false,
     "start_time": "2023-06-25T13:01:10.912302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30609e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:10.939684Z",
     "iopub.status.busy": "2023-06-25T13:01:10.939285Z",
     "iopub.status.idle": "2023-06-25T13:01:10.944008Z",
     "shell.execute_reply": "2023-06-25T13:01:10.942672Z"
    },
    "papermill": {
     "duration": 0.017249,
     "end_time": "2023-06-25T13:01:10.946605",
     "exception": false,
     "start_time": "2023-06-25T13:01:10.929356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validation_df[pred_cols].to_parquet(\"validation_pred.parquet\")\n",
    "# live_df[pred_cols].to_parquet(\"live_pred.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d94c71",
   "metadata": {
    "papermill": {
     "duration": 0.008567,
     "end_time": "2023-06-25T13:01:10.963564",
     "exception": false,
     "start_time": "2023-06-25T13:01:10.954997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Make an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50999c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:10.982205Z",
     "iopub.status.busy": "2023-06-25T13:01:10.981721Z",
     "iopub.status.idle": "2023-06-25T13:01:10.986525Z",
     "shell.execute_reply": "2023-06-25T13:01:10.985313Z"
    },
    "papermill": {
     "duration": 0.017152,
     "end_time": "2023-06-25T13:01:10.989090",
     "exception": false,
     "start_time": "2023-06-25T13:01:10.971938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # make an ensemble\n",
    "# validation_df.loc[:, \"pred_equal_weight\"] = validation_df[pred_cols].mean(axis=1)\n",
    "# live_df[\"pred_equal_weight\"] = live_df[pred_cols].mean(axis=1)\n",
    "# pred_cols.append(\"pred_equal_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93487eaf",
   "metadata": {
    "papermill": {
     "duration": 0.00802,
     "end_time": "2023-06-25T13:01:11.005554",
     "exception": false,
     "start_time": "2023-06-25T13:01:10.997534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Neutralize with risky features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49242892",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:11.024521Z",
     "iopub.status.busy": "2023-06-25T13:01:11.024104Z",
     "iopub.status.idle": "2023-06-25T13:01:11.029067Z",
     "shell.execute_reply": "2023-06-25T13:01:11.028071Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.017385,
     "end_time": "2023-06-25T13:01:11.031290",
     "exception": false,
     "start_time": "2023-06-25T13:01:11.013905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # compute feature correlations with target \n",
    "# all_feature_corrs = train_df.groupby('era').apply(lambda d: d[features].astype(float).corrwith(d[\"target\"]))\n",
    "# # compute the volatility of the feature correlations\n",
    "# feature_corr_volatility = all_feature_corrs.std()\n",
    "\n",
    "# risky_feat_library = {}\n",
    "# for pred in pred_cols:\n",
    "#     print(pred)\n",
    "#     # calculate the feature exposures of the predictions\n",
    "#     feature_exposure_list = []\n",
    "#     for feature in features:\n",
    "#         feature_exposure_list.append(np.corrcoef(validation_df[feature].astype(float), validation_df[pred])[0,1])\n",
    "#     feature_exposure_list = pd.Series(feature_exposure_list, index=features)\n",
    "#     # get list of  riskiest features\n",
    "#     risky_feat_library[pred] = (feature_exposure_list.abs()*feature_corr_volatility).sort_values(ascending=False).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5b55b1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:11.049571Z",
     "iopub.status.busy": "2023-06-25T13:01:11.049194Z",
     "iopub.status.idle": "2023-06-25T13:01:11.054716Z",
     "shell.execute_reply": "2023-06-25T13:01:11.053554Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.01782,
     "end_time": "2023-06-25T13:01:11.057432",
     "exception": false,
     "start_time": "2023-06-25T13:01:11.039612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for pred in pred_cols:\n",
    "#     for prop in [0.25, 0.5, 0.75]:\n",
    "#         for risky_feat in [100, 200, 300]:\n",
    "#             print(f\"{pred}_{prop}_neutralized_{risky_feat}\")\n",
    "#             # make a 50% feature neutral variation of one of the models\n",
    "#             validation_df[f\"{pred}_{prop}_neutralized_{risky_feat}\"] = neutralize(\n",
    "#                 df=validation_df,\n",
    "#                 columns=[f\"{pred}\"],\n",
    "#                 neutralizers=risky_feat_library[pred][:risky_feat],\n",
    "#                 proportion=prop,\n",
    "#                 normalize=True,\n",
    "#                 era_col=\"era\",\n",
    "#                 verbose=True,\n",
    "#             )\n",
    "\n",
    "#             # do the same for live data\n",
    "#             live_df[f\"{pred}_{prop}_neutralized_{risky_feat}\"] = neutralize(\n",
    "#                 df=live_df,\n",
    "#                 columns=[f\"{pred}\"],\n",
    "#                 neutralizers=risky_feat_library[pred][:risky_feat],\n",
    "#                 proportion=prop,\n",
    "#                 normalize=True,\n",
    "#                 era_col=\"era\",\n",
    "#                 verbose=True,\n",
    "#             )\n",
    "\n",
    "# pred_cols = [c for c in validation_df.columns if (c.startswith('pred'))]\n",
    "# (pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8eda364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:11.076779Z",
     "iopub.status.busy": "2023-06-25T13:01:11.076360Z",
     "iopub.status.idle": "2023-06-25T13:01:11.081148Z",
     "shell.execute_reply": "2023-06-25T13:01:11.080166Z"
    },
    "papermill": {
     "duration": 0.017196,
     "end_time": "2023-06-25T13:01:11.083726",
     "exception": false,
     "start_time": "2023-06-25T13:01:11.066530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Print correlation performance of each prediction with target\n",
    "# validation_perf_df = pd.DataFrame(columns=['corr_w_target', 'sharpe'])\n",
    "# for pred in pred_cols:\n",
    "#     corr_across_eras = validation_df.groupby('era').apply(lambda df: df[pred].corr(df['target'], method='spearman'))\n",
    "#     validation_perf_df.loc[pred,'corr_w_target'] = corr_across_eras.mean()\n",
    "#     validation_perf_df.loc[pred,'sharpe'] = corr_across_eras.mean() / corr_across_eras.std(ddof=0)\n",
    "\n",
    "# validation_perf_df.sort_values(by='corr_w_target', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db656a9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:11.102649Z",
     "iopub.status.busy": "2023-06-25T13:01:11.101581Z",
     "iopub.status.idle": "2023-06-25T13:01:11.107708Z",
     "shell.execute_reply": "2023-06-25T13:01:11.106738Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.01833,
     "end_time": "2023-06-25T13:01:11.110357",
     "exception": false,
     "start_time": "2023-06-25T13:01:11.092027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Correlation with live prediction\n",
    "# live_perf_dict = {}\n",
    "# for pred in pred_cols:\n",
    "#     corr_mean = live_df[pred].corr(live_example_preds.reset_index(drop=True), method='spearman')\n",
    "#     live_perf_dict[pred] = corr_mean\n",
    "# live_perf_df = pd.DataFrame.from_dict(live_perf_dict, orient='index', columns=['corr_w_live_predictions'])\n",
    "# live_perf_df.sort_values(by='corr_w_live_predictions', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e4237f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T13:01:11.128785Z",
     "iopub.status.busy": "2023-06-25T13:01:11.128354Z",
     "iopub.status.idle": "2023-06-25T13:01:11.132453Z",
     "shell.execute_reply": "2023-06-25T13:01:11.131579Z"
    },
    "papermill": {
     "duration": 0.016275,
     "end_time": "2023-06-25T13:01:11.134860",
     "exception": false,
     "start_time": "2023-06-25T13:01:11.118585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results_df = validation_perf_df.join(live_perf_df)\n",
    "# results_df.sort_values(by='corr_w_target', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14784.031189,
   "end_time": "2023-06-25T13:01:14.130598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-25T08:54:50.099409",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
